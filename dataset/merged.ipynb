{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Toutes les images ont été copiées avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "test1 = r\"D:\\Downloads\\projectù\\Tunisian license plate.v2i.yolov8\\test\\images\"\n",
    "train1 = r\"D:\\Downloads\\projectù\\Tunisian license plate.v2i.yolov8\\train\\images\"\n",
    "valid1 = r\"D:\\Downloads\\projectù\\Tunisian license plate.v2i.yolov8\\valid\\images\"\n",
    "test2 = r\"D:\\Downloads\\projectù\\tunisian-licensed-plates-DatasetNinja\\test\\img\"\n",
    "train2 = r\"D:\\Downloads\\projectù\\tunisian-licensed-plates-DatasetNinja\\train\\img\"\n",
    "\n",
    "sources = [test1, train1, valid1, test2, train2]\n",
    "destination = r\"D:\\Downloads\\projectù\\all_images\"\n",
    "os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "for folder in sources:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            src_path = os.path.join(folder, file)\n",
    "            dst_path = os.path.join(destination, file)\n",
    "\n",
    "            # Éviter l'écrasement des fichiers avec le même nom\n",
    "            if os.path.exists(dst_path):\n",
    "                name, ext = os.path.splitext(file)\n",
    "                dst_path = os.path.join(destination, name + \"_copy\" + ext)\n",
    "\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41338cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d’images : 1105\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dossier = r\"D:\\Downloads\\projectù\\all_images\"\n",
    "\n",
    "nb_images = len([\n",
    "    f for f in os.listdir(dossier)\n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "])\n",
    "\n",
    "print(\"Nombre total d’images :\", nb_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b8ca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Fusion terminée ! Le dossier général est : D:\\Downloads\\projectù\\merged_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# -----------------------------\n",
    "# Chemins du projet\n",
    "# -----------------------------\n",
    "project_path = r\"D:\\Downloads\\projectù\"\n",
    "yolo_path = os.path.join(project_path, \"licence plates.v1i.yolov11\")\n",
    "datasetninja_path = os.path.join(project_path, \"tunisian-licensed-plates-DatasetNinja\")\n",
    "\n",
    "# Nouveau dossier général\n",
    "general_path = os.path.join(project_path, \"merged_dataset\")\n",
    "os.makedirs(general_path, exist_ok=True)\n",
    "\n",
    "# Sous-dossiers images et labels\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    os.makedirs(os.path.join(general_path, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(general_path, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Fonction pour convertir JSON DatasetNinja -> YOLO\n",
    "# -----------------------------\n",
    "def json_to_yolo(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    yolo_lines = []\n",
    "\n",
    "    img_w = data['size']['width']\n",
    "    img_h = data['size']['height']\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        class_id = 0  # license plate\n",
    "        x1, y1 = obj['points']['exterior'][0]\n",
    "        x2, y2 = obj['points']['exterior'][1]\n",
    "\n",
    "        # Conversion en YOLO\n",
    "        x_center = ((x1 + x2) / 2) / img_w\n",
    "        y_center = ((y1 + y2) / 2) / img_h\n",
    "        width = abs(x2 - x1) / img_w\n",
    "        height = abs(y2 - y1) / img_h\n",
    "\n",
    "        yolo_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    return \"\\n\".join(yolo_lines)\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Fusion DatasetNinja -> YOLO\n",
    "# -----------------------------\n",
    "for split in [\"train\", \"test\"]:\n",
    "    ann_dir = os.path.join(datasetninja_path, split, \"ann\")\n",
    "    img_dir = os.path.join(datasetninja_path, split, \"img\")\n",
    "\n",
    "    if not os.path.exists(ann_dir):\n",
    "        print(f\"[INFO] Le dossier {ann_dir} n'existe pas, skip.\")\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(ann_dir):\n",
    "        if file.endswith(\".json\"):\n",
    "            json_file = os.path.join(ann_dir, file)\n",
    "            yolo_label = json_to_yolo(json_file)\n",
    "\n",
    "            # Nom complet avant .json\n",
    "            base_name = file[:-5]  # supprime juste \".json\"\n",
    "\n",
    "            # Cherche image correspondante\n",
    "            img_name_jpg = base_name  # le nom contient déjà .jpg\n",
    "            img_name_png = base_name.replace(\".jpg\", \".png\")  # si c'est png\n",
    "\n",
    "            src_img = None\n",
    "            if os.path.exists(os.path.join(img_dir, img_name_jpg)):\n",
    "                src_img = os.path.join(img_dir, img_name_jpg)\n",
    "                dst_img_name = img_name_jpg\n",
    "            elif os.path.exists(os.path.join(img_dir, img_name_png)):\n",
    "                src_img = os.path.join(img_dir, img_name_png)\n",
    "                dst_img_name = img_name_png\n",
    "            else:\n",
    "                print(f\"[WARN] Image correspondante pour {file} non trouvée, skip.\")\n",
    "                continue\n",
    "\n",
    "            # Copier image\n",
    "            dst_img = os.path.join(general_path, split, \"images\", dst_img_name)\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            # Sauvegarder annotation YOLO\n",
    "            label_file = os.path.join(general_path, split, \"labels\", base_name + \".txt\")\n",
    "            with open(label_file, \"w\") as f:\n",
    "                f.write(yolo_label)\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Copier les labels YOLO existants\n",
    "# -----------------------------\n",
    "# YOLO/train -> merged_dataset/train\n",
    "src_img_dir = os.path.join(yolo_path, \"train\", \"images\")\n",
    "src_label_dir = os.path.join(yolo_path, \"train\", \"labels\")\n",
    "dst_img_dir = os.path.join(general_path, \"train\", \"images\")\n",
    "dst_label_dir = os.path.join(general_path, \"train\", \"labels\")\n",
    "\n",
    "if os.path.exists(src_img_dir):\n",
    "    for file in os.listdir(src_img_dir):\n",
    "        shutil.copy2(os.path.join(src_img_dir, file), os.path.join(dst_img_dir, file))\n",
    "if os.path.exists(src_label_dir):\n",
    "    for file in os.listdir(src_label_dir):\n",
    "        shutil.copy2(os.path.join(src_label_dir, file), os.path.join(dst_label_dir, file))\n",
    "\n",
    "# YOLO/valid -> merged_dataset/valid\n",
    "src_img_dir = os.path.join(yolo_path, \"valid\", \"images\")\n",
    "src_label_dir = os.path.join(yolo_path, \"valid\", \"labels\")\n",
    "dst_img_dir = os.path.join(general_path, \"valid\", \"images\")\n",
    "dst_label_dir = os.path.join(general_path, \"valid\", \"labels\")\n",
    "\n",
    "if os.path.exists(src_img_dir):\n",
    "    for file in os.listdir(src_img_dir):\n",
    "        shutil.copy2(os.path.join(src_img_dir, file), os.path.join(dst_img_dir, file))\n",
    "if os.path.exists(src_label_dir):\n",
    "    for file in os.listdir(src_label_dir):\n",
    "        shutil.copy2(os.path.join(src_label_dir, file), os.path.join(dst_label_dir, file))\n",
    "\n",
    "print(f\"[DONE] Fusion terminée ! Le dossier général est : {general_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247599cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d’images : 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dossier = r\"D:\\Downloads\\projectù\\merged_dataset\"\n",
    "\n",
    "nb_images = len([\n",
    "    f for f in os.listdir(dossier)\n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "])\n",
    "\n",
    "print(\"Nombre total d’images :\", nb_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d66e0356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Fusion terminée ! Le dossier général est : D:\\Downloads\\projectù\\merged_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# -----------------------------\n",
    "# Chemins du projet\n",
    "# -----------------------------\n",
    "project_path = r\"D:\\Downloads\\projectù\"\n",
    "yolo_path = os.path.join(project_path, \"licence plates.v1i.yolov11\")\n",
    "datasetninja_path = os.path.join(project_path, \"tunisian-licensed-plates-DatasetNinja\")\n",
    "\n",
    "# Nouveau dossier général\n",
    "general_path = os.path.join(project_path, \"merged_dataset\")\n",
    "os.makedirs(general_path, exist_ok=True)\n",
    "\n",
    "# Sous-dossiers images et labels\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    os.makedirs(os.path.join(general_path, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(general_path, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Fonction pour convertir JSON DatasetNinja -> YOLO\n",
    "# -----------------------------\n",
    "def json_to_yolo(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    yolo_lines = []\n",
    "\n",
    "    img_w = data['size']['width']\n",
    "    img_h = data['size']['height']\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        class_id = 0  # license plate\n",
    "        x1, y1 = obj['points']['exterior'][0]\n",
    "        x2, y2 = obj['points']['exterior'][1]\n",
    "\n",
    "        # Conversion en YOLO format\n",
    "        x_center = ((x1 + x2) / 2) / img_w\n",
    "        y_center = ((y1 + y2) / 2) / img_h\n",
    "        width = abs(x2 - x1) / img_w\n",
    "        height = abs(y2 - y1) / img_h\n",
    "\n",
    "        yolo_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    return \"\\n\".join(yolo_lines)\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Fusion DatasetNinja -> YOLO\n",
    "# -----------------------------\n",
    "for split in [\"train\", \"test\"]:\n",
    "    ann_dir = os.path.join(datasetninja_path, split, \"ann\")\n",
    "    img_dir = os.path.join(datasetninja_path, split, \"img\")\n",
    "\n",
    "    if not os.path.exists(ann_dir):\n",
    "        print(f\"[INFO] Le dossier {ann_dir} n'existe pas, skip.\")\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(ann_dir):\n",
    "        if file.endswith(\".json\"):\n",
    "            json_file = os.path.join(ann_dir, file)\n",
    "            yolo_label = json_to_yolo(json_file)\n",
    "\n",
    "            # Nom complet avant .json\n",
    "            base_name = file[:-5]  # supprime \".json\"\n",
    "\n",
    "            # Cherche image correspondante\n",
    "            img_name_jpg = base_name  # ex: 142.jpg\n",
    "            img_name_png = base_name.replace(\".jpg\", \".png\")\n",
    "\n",
    "            src_img = None\n",
    "            final_img_name = None\n",
    "            if os.path.exists(os.path.join(img_dir, img_name_jpg)):\n",
    "                src_img = os.path.join(img_dir, img_name_jpg)\n",
    "                final_img_name = img_name_jpg\n",
    "            elif os.path.exists(os.path.join(img_dir, img_name_png)):\n",
    "                src_img = os.path.join(img_dir, img_name_png)\n",
    "                final_img_name = img_name_png\n",
    "            else:\n",
    "                print(f\"[WARN] Image correspondante pour {file} non trouvée, skip.\")\n",
    "                continue\n",
    "\n",
    "            # Copier image\n",
    "            dst_img = os.path.join(general_path, split, \"images\", final_img_name)\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            # Sauvegarder label YOLO avec **le même nom de base que l'image**\n",
    "            label_file = os.path.join(general_path, split, \"labels\", os.path.splitext(final_img_name)[0] + \".txt\")\n",
    "            with open(label_file, \"w\") as f:\n",
    "                f.write(yolo_label)\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Copier les labels YOLO existants\n",
    "# -----------------------------\n",
    "def copy_yolo_split(split):\n",
    "    src_img_dir = os.path.join(yolo_path, split, \"images\")\n",
    "    src_label_dir = os.path.join(yolo_path, split, \"labels\")\n",
    "    dst_img_dir = os.path.join(general_path, split, \"images\")\n",
    "    dst_label_dir = os.path.join(general_path, split, \"labels\")\n",
    "\n",
    "    if os.path.exists(src_img_dir):\n",
    "        for file in os.listdir(src_img_dir):\n",
    "            shutil.copy2(os.path.join(src_img_dir, file), os.path.join(dst_img_dir, file))\n",
    "    if os.path.exists(src_label_dir):\n",
    "        for file in os.listdir(src_label_dir):\n",
    "            shutil.copy2(os.path.join(src_label_dir, file), os.path.join(dst_label_dir, file))\n",
    "\n",
    "copy_yolo_split(\"train\")\n",
    "copy_yolo_split(\"valid\")\n",
    "\n",
    "print(f\"[DONE] Fusion terminée ! Le dossier général est : {general_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcf1563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Images: 697, Labels: 1264\n",
      "[VALID] Images: 41, Labels: 41\n",
      "[TEST] Images: 142, Labels: 284\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Chemin du dossier fusionné\n",
    "general_path = r\"D:\\Downloads\\projectù\\merged_dataset\"\n",
    "\n",
    "# Vérification des splits\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    images_dir = os.path.join(general_path, split, \"images\")\n",
    "    labels_dir = os.path.join(general_path, split, \"labels\")\n",
    "\n",
    "    # Compter images (.jpg ou .png)\n",
    "    num_images = len([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    # Compter labels (.txt)\n",
    "    num_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith(\".txt\")])\n",
    "\n",
    "    print(f\"[{split.upper()}] Images: {num_images}, Labels: {num_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baac7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "print(142*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e9adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED] 0.txt\n",
      "[REMOVED] 1.txt\n",
      "[REMOVED] 10.txt\n",
      "[REMOVED] 100.txt\n",
      "[REMOVED] 101.txt\n",
      "[REMOVED] 102.txt\n",
      "[REMOVED] 103.txt\n",
      "[REMOVED] 104.txt\n",
      "[REMOVED] 105.txt\n",
      "[REMOVED] 106.txt\n",
      "[REMOVED] 107.txt\n",
      "[REMOVED] 108.txt\n",
      "[REMOVED] 109.txt\n",
      "[REMOVED] 11.txt\n",
      "[REMOVED] 110.txt\n",
      "[REMOVED] 111.txt\n",
      "[REMOVED] 112.txt\n",
      "[REMOVED] 113.txt\n",
      "[REMOVED] 114.txt\n",
      "[REMOVED] 115.txt\n",
      "[REMOVED] 116.txt\n",
      "[REMOVED] 117.txt\n",
      "[REMOVED] 118.txt\n",
      "[REMOVED] 119.txt\n",
      "[REMOVED] 12.txt\n",
      "[REMOVED] 120.txt\n",
      "[REMOVED] 121.txt\n",
      "[REMOVED] 122.txt\n",
      "[REMOVED] 123.txt\n",
      "[REMOVED] 124.txt\n",
      "[REMOVED] 125.txt\n",
      "[REMOVED] 126.txt\n",
      "[REMOVED] 127.txt\n",
      "[REMOVED] 128.txt\n",
      "[REMOVED] 129.txt\n",
      "[REMOVED] 13.txt\n",
      "[REMOVED] 130.txt\n",
      "[REMOVED] 131.txt\n",
      "[REMOVED] 132.txt\n",
      "[REMOVED] 133.txt\n",
      "[REMOVED] 134.txt\n",
      "[REMOVED] 135.txt\n",
      "[REMOVED] 136.txt\n",
      "[REMOVED] 137.txt\n",
      "[REMOVED] 138.txt\n",
      "[REMOVED] 139.txt\n",
      "[REMOVED] 14.txt\n",
      "[REMOVED] 140.txt\n",
      "[REMOVED] 141.txt\n",
      "[REMOVED] 15.txt\n",
      "[REMOVED] 16.txt\n",
      "[REMOVED] 17.txt\n",
      "[REMOVED] 18.txt\n",
      "[REMOVED] 19.txt\n",
      "[REMOVED] 2.txt\n",
      "[REMOVED] 20.txt\n",
      "[REMOVED] 21.txt\n",
      "[REMOVED] 22.txt\n",
      "[REMOVED] 23.txt\n",
      "[REMOVED] 24.txt\n",
      "[REMOVED] 25.txt\n",
      "[REMOVED] 26.txt\n",
      "[REMOVED] 27.txt\n",
      "[REMOVED] 28.txt\n",
      "[REMOVED] 29.txt\n",
      "[REMOVED] 3.txt\n",
      "[REMOVED] 30.txt\n",
      "[REMOVED] 31.txt\n",
      "[REMOVED] 32.txt\n",
      "[REMOVED] 33.txt\n",
      "[REMOVED] 34.txt\n",
      "[REMOVED] 35.txt\n",
      "[REMOVED] 36.txt\n",
      "[REMOVED] 37.txt\n",
      "[REMOVED] 38.txt\n",
      "[REMOVED] 39.txt\n",
      "[REMOVED] 4.txt\n",
      "[REMOVED] 40.txt\n",
      "[REMOVED] 41.txt\n",
      "[REMOVED] 42.txt\n",
      "[REMOVED] 43.txt\n",
      "[REMOVED] 44.txt\n",
      "[REMOVED] 45.txt\n",
      "[REMOVED] 46.txt\n",
      "[REMOVED] 47.txt\n",
      "[REMOVED] 48.txt\n",
      "[REMOVED] 49.txt\n",
      "[REMOVED] 5.txt\n",
      "[REMOVED] 50.txt\n",
      "[REMOVED] 51.txt\n",
      "[REMOVED] 52.txt\n",
      "[REMOVED] 53.txt\n",
      "[REMOVED] 54.txt\n",
      "[REMOVED] 55.txt\n",
      "[REMOVED] 56.txt\n",
      "[REMOVED] 57.txt\n",
      "[REMOVED] 58.txt\n",
      "[REMOVED] 59.txt\n",
      "[REMOVED] 6.txt\n",
      "[REMOVED] 60.txt\n",
      "[REMOVED] 61.txt\n",
      "[REMOVED] 62.txt\n",
      "[REMOVED] 63.txt\n",
      "[REMOVED] 64.txt\n",
      "[REMOVED] 65.txt\n",
      "[REMOVED] 66.txt\n",
      "[REMOVED] 67.txt\n",
      "[REMOVED] 68.txt\n",
      "[REMOVED] 69.txt\n",
      "[REMOVED] 7.txt\n",
      "[REMOVED] 70.txt\n",
      "[REMOVED] 71.txt\n",
      "[REMOVED] 72.txt\n",
      "[REMOVED] 73.txt\n",
      "[REMOVED] 74.txt\n",
      "[REMOVED] 75.txt\n",
      "[REMOVED] 76.txt\n",
      "[REMOVED] 77.txt\n",
      "[REMOVED] 78.txt\n",
      "[REMOVED] 79.txt\n",
      "[REMOVED] 8.txt\n",
      "[REMOVED] 80.txt\n",
      "[REMOVED] 81.txt\n",
      "[REMOVED] 82.txt\n",
      "[REMOVED] 83.txt\n",
      "[REMOVED] 84.txt\n",
      "[REMOVED] 85.txt\n",
      "[REMOVED] 86.txt\n",
      "[REMOVED] 87.txt\n",
      "[REMOVED] 88.txt\n",
      "[REMOVED] 89.txt\n",
      "[REMOVED] 9.txt\n",
      "[REMOVED] 90.txt\n",
      "[REMOVED] 91.txt\n",
      "[REMOVED] 92.txt\n",
      "[REMOVED] 93.txt\n",
      "[REMOVED] 94.txt\n",
      "[REMOVED] 95.txt\n",
      "[REMOVED] 96.txt\n",
      "[REMOVED] 97.txt\n",
      "[REMOVED] 98.txt\n",
      "[REMOVED] 99.txt\n",
      "[DONE] Labels doublons supprimés dans test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Dossier test\n",
    "test_labels_dir = r\"D:\\Downloads\\projectù\\merged_dataset\\test\\labels\"\n",
    "test_images_dir = r\"D:\\Downloads\\projectù\\merged_dataset\\test\\images\"\n",
    "\n",
    "# Lister toutes les images\n",
    "image_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "# Pour chaque label dans labels/, supprimer celui qui **ne correspond pas exactement à l'image**\n",
    "for label_file in os.listdir(test_labels_dir):\n",
    "    if not label_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    # Base du nom du label\n",
    "    base_label = label_file[:-4]  # retire .txt\n",
    "\n",
    "    # Si le label ne correspond à aucune image, on le supprime\n",
    "    if base_label not in image_files:\n",
    "        label_path = os.path.join(test_labels_dir, label_file)\n",
    "        os.remove(label_path)\n",
    "        print(f\"[REMOVED] {label_file}\")\n",
    "\n",
    "print(\"[DONE] Labels doublons supprimés dans test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e547465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Images: 697, Labels: 1264\n",
      "[VALID] Images: 41, Labels: 41\n",
      "[TEST] Images: 142, Labels: 142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Chemin du dossier fusionné\n",
    "general_path = r\"D:\\Downloads\\projectù\\merged_dataset\"\n",
    "\n",
    "# Vérification des splits\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    images_dir = os.path.join(general_path, split, \"images\")\n",
    "    labels_dir = os.path.join(general_path, split, \"labels\")\n",
    "\n",
    "    # Compter images (.jpg ou .png)\n",
    "    num_images = len([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    # Compter labels (.txt)\n",
    "    num_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith(\".txt\")])\n",
    "\n",
    "    print(f\"[{split.upper()}] Images: {num_images}, Labels: {num_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87ad13b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REMOVED] 142.txt\n",
      "[REMOVED] 143.txt\n",
      "[REMOVED] 144.txt\n",
      "[REMOVED] 145.txt\n",
      "[REMOVED] 146.txt\n",
      "[REMOVED] 147.txt\n",
      "[REMOVED] 148.txt\n",
      "[REMOVED] 149.txt\n",
      "[REMOVED] 150.txt\n",
      "[REMOVED] 151.txt\n",
      "[REMOVED] 152.txt\n",
      "[REMOVED] 153.txt\n",
      "[REMOVED] 154.txt\n",
      "[REMOVED] 155.txt\n",
      "[REMOVED] 156.txt\n",
      "[REMOVED] 157.txt\n",
      "[REMOVED] 158.txt\n",
      "[REMOVED] 159.txt\n",
      "[REMOVED] 160.txt\n",
      "[REMOVED] 161.txt\n",
      "[REMOVED] 162.txt\n",
      "[REMOVED] 163.txt\n",
      "[REMOVED] 164.txt\n",
      "[REMOVED] 165.txt\n",
      "[REMOVED] 166.txt\n",
      "[REMOVED] 167.txt\n",
      "[REMOVED] 168.txt\n",
      "[REMOVED] 169.txt\n",
      "[REMOVED] 170.txt\n",
      "[REMOVED] 171.txt\n",
      "[REMOVED] 172.txt\n",
      "[REMOVED] 173.txt\n",
      "[REMOVED] 174.txt\n",
      "[REMOVED] 175.txt\n",
      "[REMOVED] 176.txt\n",
      "[REMOVED] 177.txt\n",
      "[REMOVED] 178.txt\n",
      "[REMOVED] 179.txt\n",
      "[REMOVED] 180.txt\n",
      "[REMOVED] 181.txt\n",
      "[REMOVED] 182.txt\n",
      "[REMOVED] 183.txt\n",
      "[REMOVED] 184.txt\n",
      "[REMOVED] 185.txt\n",
      "[REMOVED] 186.txt\n",
      "[REMOVED] 187.txt\n",
      "[REMOVED] 188.txt\n",
      "[REMOVED] 189.txt\n",
      "[REMOVED] 190.txt\n",
      "[REMOVED] 191.txt\n",
      "[REMOVED] 192.txt\n",
      "[REMOVED] 193.txt\n",
      "[REMOVED] 194.txt\n",
      "[REMOVED] 195.txt\n",
      "[REMOVED] 196.txt\n",
      "[REMOVED] 197.txt\n",
      "[REMOVED] 198.txt\n",
      "[REMOVED] 199.txt\n",
      "[REMOVED] 200.txt\n",
      "[REMOVED] 201.txt\n",
      "[REMOVED] 202.txt\n",
      "[REMOVED] 203.txt\n",
      "[REMOVED] 204.txt\n",
      "[REMOVED] 205.txt\n",
      "[REMOVED] 206.txt\n",
      "[REMOVED] 207.txt\n",
      "[REMOVED] 208.txt\n",
      "[REMOVED] 209.txt\n",
      "[REMOVED] 210.txt\n",
      "[REMOVED] 211.txt\n",
      "[REMOVED] 212.txt\n",
      "[REMOVED] 213.txt\n",
      "[REMOVED] 214.txt\n",
      "[REMOVED] 215.txt\n",
      "[REMOVED] 216.txt\n",
      "[REMOVED] 217.txt\n",
      "[REMOVED] 218.txt\n",
      "[REMOVED] 219.txt\n",
      "[REMOVED] 220.txt\n",
      "[REMOVED] 221.txt\n",
      "[REMOVED] 222.txt\n",
      "[REMOVED] 223.txt\n",
      "[REMOVED] 224.txt\n",
      "[REMOVED] 225.txt\n",
      "[REMOVED] 226.txt\n",
      "[REMOVED] 227.txt\n",
      "[REMOVED] 228.txt\n",
      "[REMOVED] 229.txt\n",
      "[REMOVED] 230.txt\n",
      "[REMOVED] 231.txt\n",
      "[REMOVED] 232.txt\n",
      "[REMOVED] 233.txt\n",
      "[REMOVED] 234.txt\n",
      "[REMOVED] 235.txt\n",
      "[REMOVED] 236.txt\n",
      "[REMOVED] 237.txt\n",
      "[REMOVED] 238.txt\n",
      "[REMOVED] 239.txt\n",
      "[REMOVED] 240.txt\n",
      "[REMOVED] 241.txt\n",
      "[REMOVED] 242.txt\n",
      "[REMOVED] 243.txt\n",
      "[REMOVED] 244.txt\n",
      "[REMOVED] 245.txt\n",
      "[REMOVED] 246.txt\n",
      "[REMOVED] 247.txt\n",
      "[REMOVED] 248.txt\n",
      "[REMOVED] 249.txt\n",
      "[REMOVED] 250.txt\n",
      "[REMOVED] 251.txt\n",
      "[REMOVED] 252.txt\n",
      "[REMOVED] 253.txt\n",
      "[REMOVED] 254.txt\n",
      "[REMOVED] 255.txt\n",
      "[REMOVED] 256.txt\n",
      "[REMOVED] 257.txt\n",
      "[REMOVED] 258.txt\n",
      "[REMOVED] 259.txt\n",
      "[REMOVED] 260.txt\n",
      "[REMOVED] 261.txt\n",
      "[REMOVED] 262.txt\n",
      "[REMOVED] 263.txt\n",
      "[REMOVED] 264.txt\n",
      "[REMOVED] 265.txt\n",
      "[REMOVED] 266.txt\n",
      "[REMOVED] 267.txt\n",
      "[REMOVED] 268.txt\n",
      "[REMOVED] 269.txt\n",
      "[REMOVED] 270.txt\n",
      "[REMOVED] 271.txt\n",
      "[REMOVED] 272.txt\n",
      "[REMOVED] 273.txt\n",
      "[REMOVED] 274.txt\n",
      "[REMOVED] 275.txt\n",
      "[REMOVED] 276.txt\n",
      "[REMOVED] 277.txt\n",
      "[REMOVED] 278.txt\n",
      "[REMOVED] 279.txt\n",
      "[REMOVED] 280.txt\n",
      "[REMOVED] 281.txt\n",
      "[REMOVED] 282.txt\n",
      "[REMOVED] 283.txt\n",
      "[REMOVED] 284.txt\n",
      "[REMOVED] 285.txt\n",
      "[REMOVED] 286.txt\n",
      "[REMOVED] 287.txt\n",
      "[REMOVED] 288.txt\n",
      "[REMOVED] 289.txt\n",
      "[REMOVED] 290.txt\n",
      "[REMOVED] 291.txt\n",
      "[REMOVED] 292.txt\n",
      "[REMOVED] 293.txt\n",
      "[REMOVED] 294.txt\n",
      "[REMOVED] 295.txt\n",
      "[REMOVED] 296.txt\n",
      "[REMOVED] 297.txt\n",
      "[REMOVED] 298.txt\n",
      "[REMOVED] 299.txt\n",
      "[REMOVED] 300.txt\n",
      "[REMOVED] 301.txt\n",
      "[REMOVED] 302.txt\n",
      "[REMOVED] 303.txt\n",
      "[REMOVED] 304.txt\n",
      "[REMOVED] 305.txt\n",
      "[REMOVED] 306.txt\n",
      "[REMOVED] 307.txt\n",
      "[REMOVED] 308.txt\n",
      "[REMOVED] 309.txt\n",
      "[REMOVED] 310.txt\n",
      "[REMOVED] 311.txt\n",
      "[REMOVED] 312.txt\n",
      "[REMOVED] 313.txt\n",
      "[REMOVED] 314.txt\n",
      "[REMOVED] 315.txt\n",
      "[REMOVED] 316.txt\n",
      "[REMOVED] 317.txt\n",
      "[REMOVED] 318.txt\n",
      "[REMOVED] 319.txt\n",
      "[REMOVED] 320.txt\n",
      "[REMOVED] 321.txt\n",
      "[REMOVED] 322.txt\n",
      "[REMOVED] 323.txt\n",
      "[REMOVED] 324.txt\n",
      "[REMOVED] 325.txt\n",
      "[REMOVED] 326.txt\n",
      "[REMOVED] 327.txt\n",
      "[REMOVED] 328.txt\n",
      "[REMOVED] 329.txt\n",
      "[REMOVED] 330.txt\n",
      "[REMOVED] 331.txt\n",
      "[REMOVED] 332.txt\n",
      "[REMOVED] 333.txt\n",
      "[REMOVED] 334.txt\n",
      "[REMOVED] 335.txt\n",
      "[REMOVED] 336.txt\n",
      "[REMOVED] 337.txt\n",
      "[REMOVED] 338.txt\n",
      "[REMOVED] 339.txt\n",
      "[REMOVED] 340.txt\n",
      "[REMOVED] 341.txt\n",
      "[REMOVED] 342.txt\n",
      "[REMOVED] 343.txt\n",
      "[REMOVED] 344.txt\n",
      "[REMOVED] 345.txt\n",
      "[REMOVED] 346.txt\n",
      "[REMOVED] 347.txt\n",
      "[REMOVED] 348.txt\n",
      "[REMOVED] 349.txt\n",
      "[REMOVED] 350.txt\n",
      "[REMOVED] 351.txt\n",
      "[REMOVED] 352.txt\n",
      "[REMOVED] 353.txt\n",
      "[REMOVED] 354.txt\n",
      "[REMOVED] 355.txt\n",
      "[REMOVED] 356.txt\n",
      "[REMOVED] 357.txt\n",
      "[REMOVED] 358.txt\n",
      "[REMOVED] 359.txt\n",
      "[REMOVED] 360.txt\n",
      "[REMOVED] 361.txt\n",
      "[REMOVED] 362.txt\n",
      "[REMOVED] 363.txt\n",
      "[REMOVED] 364.txt\n",
      "[REMOVED] 365.txt\n",
      "[REMOVED] 366.txt\n",
      "[REMOVED] 367.txt\n",
      "[REMOVED] 368.txt\n",
      "[REMOVED] 369.txt\n",
      "[REMOVED] 370.txt\n",
      "[REMOVED] 371.txt\n",
      "[REMOVED] 372.txt\n",
      "[REMOVED] 373.txt\n",
      "[REMOVED] 374.txt\n",
      "[REMOVED] 375.txt\n",
      "[REMOVED] 376.txt\n",
      "[REMOVED] 377.txt\n",
      "[REMOVED] 378.txt\n",
      "[REMOVED] 379.txt\n",
      "[REMOVED] 380.txt\n",
      "[REMOVED] 381.txt\n",
      "[REMOVED] 382.txt\n",
      "[REMOVED] 383.txt\n",
      "[REMOVED] 384.txt\n",
      "[REMOVED] 385.txt\n",
      "[REMOVED] 386.txt\n",
      "[REMOVED] 387.txt\n",
      "[REMOVED] 388.txt\n",
      "[REMOVED] 389.txt\n",
      "[REMOVED] 390.txt\n",
      "[REMOVED] 391.txt\n",
      "[REMOVED] 392.txt\n",
      "[REMOVED] 393.txt\n",
      "[REMOVED] 394.txt\n",
      "[REMOVED] 395.txt\n",
      "[REMOVED] 396.txt\n",
      "[REMOVED] 397.txt\n",
      "[REMOVED] 398.txt\n",
      "[REMOVED] 399.txt\n",
      "[REMOVED] 400.txt\n",
      "[REMOVED] 401.txt\n",
      "[REMOVED] 402.txt\n",
      "[REMOVED] 403.txt\n",
      "[REMOVED] 404.txt\n",
      "[REMOVED] 405.txt\n",
      "[REMOVED] 406.txt\n",
      "[REMOVED] 407.txt\n",
      "[REMOVED] 408.txt\n",
      "[REMOVED] 409.txt\n",
      "[REMOVED] 410.txt\n",
      "[REMOVED] 411.txt\n",
      "[REMOVED] 412.txt\n",
      "[REMOVED] 413.txt\n",
      "[REMOVED] 414.txt\n",
      "[REMOVED] 415.txt\n",
      "[REMOVED] 416.txt\n",
      "[REMOVED] 417.txt\n",
      "[REMOVED] 418.txt\n",
      "[REMOVED] 419.txt\n",
      "[REMOVED] 420.txt\n",
      "[REMOVED] 421.txt\n",
      "[REMOVED] 422.txt\n",
      "[REMOVED] 423.txt\n",
      "[REMOVED] 424.txt\n",
      "[REMOVED] 425.txt\n",
      "[REMOVED] 426.txt\n",
      "[REMOVED] 427.txt\n",
      "[REMOVED] 428.txt\n",
      "[REMOVED] 429.txt\n",
      "[REMOVED] 430.txt\n",
      "[REMOVED] 431.txt\n",
      "[REMOVED] 432.txt\n",
      "[REMOVED] 433.txt\n",
      "[REMOVED] 434.txt\n",
      "[REMOVED] 435.txt\n",
      "[REMOVED] 436.txt\n",
      "[REMOVED] 437.txt\n",
      "[REMOVED] 438.txt\n",
      "[REMOVED] 439.txt\n",
      "[REMOVED] 440.txt\n",
      "[REMOVED] 441.txt\n",
      "[REMOVED] 442.txt\n",
      "[REMOVED] 443.txt\n",
      "[REMOVED] 444.txt\n",
      "[REMOVED] 445.txt\n",
      "[REMOVED] 446.txt\n",
      "[REMOVED] 447.txt\n",
      "[REMOVED] 448.txt\n",
      "[REMOVED] 449.txt\n",
      "[REMOVED] 450.txt\n",
      "[REMOVED] 451.txt\n",
      "[REMOVED] 452.txt\n",
      "[REMOVED] 453.txt\n",
      "[REMOVED] 454.txt\n",
      "[REMOVED] 455.txt\n",
      "[REMOVED] 456.txt\n",
      "[REMOVED] 457.txt\n",
      "[REMOVED] 458.txt\n",
      "[REMOVED] 459.txt\n",
      "[REMOVED] 460.txt\n",
      "[REMOVED] 461.txt\n",
      "[REMOVED] 462.txt\n",
      "[REMOVED] 463.txt\n",
      "[REMOVED] 464.txt\n",
      "[REMOVED] 465.txt\n",
      "[REMOVED] 466.txt\n",
      "[REMOVED] 467.txt\n",
      "[REMOVED] 468.txt\n",
      "[REMOVED] 469.txt\n",
      "[REMOVED] 470.txt\n",
      "[REMOVED] 471.txt\n",
      "[REMOVED] 472.txt\n",
      "[REMOVED] 473.txt\n",
      "[REMOVED] 474.txt\n",
      "[REMOVED] 475.txt\n",
      "[REMOVED] 476.txt\n",
      "[REMOVED] 477.txt\n",
      "[REMOVED] 478.txt\n",
      "[REMOVED] 479.txt\n",
      "[REMOVED] 480.txt\n",
      "[REMOVED] 481.txt\n",
      "[REMOVED] 482.txt\n",
      "[REMOVED] 483.txt\n",
      "[REMOVED] 484.txt\n",
      "[REMOVED] 485.txt\n",
      "[REMOVED] 486.txt\n",
      "[REMOVED] 487.txt\n",
      "[REMOVED] 488.txt\n",
      "[REMOVED] 489.txt\n",
      "[REMOVED] 490.txt\n",
      "[REMOVED] 491.txt\n",
      "[REMOVED] 492.txt\n",
      "[REMOVED] 493.txt\n",
      "[REMOVED] 494.txt\n",
      "[REMOVED] 495.txt\n",
      "[REMOVED] 496.txt\n",
      "[REMOVED] 497.txt\n",
      "[REMOVED] 498.txt\n",
      "[REMOVED] 499.txt\n",
      "[REMOVED] 500.txt\n",
      "[REMOVED] 501.txt\n",
      "[REMOVED] 502.txt\n",
      "[REMOVED] 503.txt\n",
      "[REMOVED] 504.txt\n",
      "[REMOVED] 505.txt\n",
      "[REMOVED] 506.txt\n",
      "[REMOVED] 507.txt\n",
      "[REMOVED] 508.txt\n",
      "[REMOVED] 509.txt\n",
      "[REMOVED] 510.txt\n",
      "[REMOVED] 511.txt\n",
      "[REMOVED] 512.txt\n",
      "[REMOVED] 513.txt\n",
      "[REMOVED] 514.txt\n",
      "[REMOVED] 515.txt\n",
      "[REMOVED] 516.txt\n",
      "[REMOVED] 517.txt\n",
      "[REMOVED] 518.txt\n",
      "[REMOVED] 519.txt\n",
      "[REMOVED] 520.txt\n",
      "[REMOVED] 521.txt\n",
      "[REMOVED] 522.txt\n",
      "[REMOVED] 523.txt\n",
      "[REMOVED] 524.txt\n",
      "[REMOVED] 525.txt\n",
      "[REMOVED] 526.txt\n",
      "[REMOVED] 527.txt\n",
      "[REMOVED] 528.txt\n",
      "[REMOVED] 529.txt\n",
      "[REMOVED] 530.txt\n",
      "[REMOVED] 531.txt\n",
      "[REMOVED] 532.txt\n",
      "[REMOVED] 533.txt\n",
      "[REMOVED] 534.txt\n",
      "[REMOVED] 535.txt\n",
      "[REMOVED] 536.txt\n",
      "[REMOVED] 537.txt\n",
      "[REMOVED] 538.txt\n",
      "[REMOVED] 539.txt\n",
      "[REMOVED] 540.txt\n",
      "[REMOVED] 541.txt\n",
      "[REMOVED] 542.txt\n",
      "[REMOVED] 543.txt\n",
      "[REMOVED] 544.txt\n",
      "[REMOVED] 545.txt\n",
      "[REMOVED] 546.txt\n",
      "[REMOVED] 547.txt\n",
      "[REMOVED] 548.txt\n",
      "[REMOVED] 549.txt\n",
      "[REMOVED] 550.txt\n",
      "[REMOVED] 551.txt\n",
      "[REMOVED] 552.txt\n",
      "[REMOVED] 553.txt\n",
      "[REMOVED] 554.txt\n",
      "[REMOVED] 555.txt\n",
      "[REMOVED] 556.txt\n",
      "[REMOVED] 557.txt\n",
      "[REMOVED] 558.txt\n",
      "[REMOVED] 559.txt\n",
      "[REMOVED] 560.txt\n",
      "[REMOVED] 561.txt\n",
      "[REMOVED] 562.txt\n",
      "[REMOVED] 563.txt\n",
      "[REMOVED] 564.txt\n",
      "[REMOVED] 565.txt\n",
      "[REMOVED] 566.txt\n",
      "[REMOVED] 567.txt\n",
      "[REMOVED] 568.txt\n",
      "[REMOVED] 569.txt\n",
      "[REMOVED] 570.txt\n",
      "[REMOVED] 571.txt\n",
      "[REMOVED] 572.txt\n",
      "[REMOVED] 573.txt\n",
      "[REMOVED] 574.txt\n",
      "[REMOVED] 575.txt\n",
      "[REMOVED] 576.txt\n",
      "[REMOVED] 577.txt\n",
      "[REMOVED] 578.txt\n",
      "[REMOVED] 579.txt\n",
      "[REMOVED] 580.txt\n",
      "[REMOVED] 581.txt\n",
      "[REMOVED] 582.txt\n",
      "[REMOVED] 583.txt\n",
      "[REMOVED] 584.txt\n",
      "[REMOVED] 585.txt\n",
      "[REMOVED] 586.txt\n",
      "[REMOVED] 587.txt\n",
      "[REMOVED] 588.txt\n",
      "[REMOVED] 589.txt\n",
      "[REMOVED] 590.txt\n",
      "[REMOVED] 591.txt\n",
      "[REMOVED] 592.txt\n",
      "[REMOVED] 593.txt\n",
      "[REMOVED] 594.txt\n",
      "[REMOVED] 595.txt\n",
      "[REMOVED] 596.txt\n",
      "[REMOVED] 597.txt\n",
      "[REMOVED] 598.txt\n",
      "[REMOVED] 599.txt\n",
      "[REMOVED] 600.txt\n",
      "[REMOVED] 601.txt\n",
      "[REMOVED] 602.txt\n",
      "[REMOVED] 603.txt\n",
      "[REMOVED] 604.txt\n",
      "[REMOVED] 605.txt\n",
      "[REMOVED] 606.txt\n",
      "[REMOVED] 607.txt\n",
      "[REMOVED] 608.txt\n",
      "[REMOVED] 609.txt\n",
      "[REMOVED] 610.txt\n",
      "[REMOVED] 611.txt\n",
      "[REMOVED] 612.txt\n",
      "[REMOVED] 613.txt\n",
      "[REMOVED] 614.txt\n",
      "[REMOVED] 615.txt\n",
      "[REMOVED] 616.txt\n",
      "[REMOVED] 617.txt\n",
      "[REMOVED] 618.txt\n",
      "[REMOVED] 619.txt\n",
      "[REMOVED] 620.txt\n",
      "[REMOVED] 621.txt\n",
      "[REMOVED] 622.txt\n",
      "[REMOVED] 623.txt\n",
      "[REMOVED] 624.txt\n",
      "[REMOVED] 625.txt\n",
      "[REMOVED] 626.txt\n",
      "[REMOVED] 627.txt\n",
      "[REMOVED] 628.txt\n",
      "[REMOVED] 629.txt\n",
      "[REMOVED] 630.txt\n",
      "[REMOVED] 631.txt\n",
      "[REMOVED] 632.txt\n",
      "[REMOVED] 633.txt\n",
      "[REMOVED] 634.txt\n",
      "[REMOVED] 635.txt\n",
      "[REMOVED] 636.txt\n",
      "[REMOVED] 637.txt\n",
      "[REMOVED] 638.txt\n",
      "[REMOVED] 639.txt\n",
      "[REMOVED] 640.txt\n",
      "[REMOVED] 641.txt\n",
      "[REMOVED] 642.txt\n",
      "[REMOVED] 643.txt\n",
      "[REMOVED] 644.txt\n",
      "[REMOVED] 645.txt\n",
      "[REMOVED] 646.txt\n",
      "[REMOVED] 647.txt\n",
      "[REMOVED] 648.txt\n",
      "[REMOVED] 649.txt\n",
      "[REMOVED] 650.txt\n",
      "[REMOVED] 651.txt\n",
      "[REMOVED] 652.txt\n",
      "[REMOVED] 653.txt\n",
      "[REMOVED] 654.txt\n",
      "[REMOVED] 655.txt\n",
      "[REMOVED] 656.txt\n",
      "[REMOVED] 657.txt\n",
      "[REMOVED] 658.txt\n",
      "[REMOVED] 659.txt\n",
      "[REMOVED] 660.txt\n",
      "[REMOVED] 661.txt\n",
      "[REMOVED] 662.txt\n",
      "[REMOVED] 663.txt\n",
      "[REMOVED] 664.txt\n",
      "[REMOVED] 665.txt\n",
      "[REMOVED] 666.txt\n",
      "[REMOVED] 667.txt\n",
      "[REMOVED] 668.txt\n",
      "[REMOVED] 669.txt\n",
      "[REMOVED] 670.txt\n",
      "[REMOVED] 671.txt\n",
      "[REMOVED] 672.txt\n",
      "[REMOVED] 673.txt\n",
      "[REMOVED] 674.txt\n",
      "[REMOVED] 675.txt\n",
      "[REMOVED] 676.txt\n",
      "[REMOVED] 677.txt\n",
      "[REMOVED] 678.txt\n",
      "[REMOVED] 679.txt\n",
      "[REMOVED] 680.txt\n",
      "[REMOVED] 681.txt\n",
      "[REMOVED] 682.txt\n",
      "[REMOVED] 683.txt\n",
      "[REMOVED] 684.txt\n",
      "[REMOVED] 685.txt\n",
      "[REMOVED] 686.txt\n",
      "[REMOVED] 687.txt\n",
      "[REMOVED] 688.txt\n",
      "[REMOVED] 689.txt\n",
      "[REMOVED] 690.txt\n",
      "[REMOVED] 691.txt\n",
      "[REMOVED] 692.txt\n",
      "[REMOVED] 693.txt\n",
      "[REMOVED] 694.txt\n",
      "[REMOVED] 695.txt\n",
      "[REMOVED] 696.txt\n",
      "[REMOVED] 697.txt\n",
      "[REMOVED] 698.txt\n",
      "[REMOVED] 699.txt\n",
      "[REMOVED] 700.txt\n",
      "[REMOVED] 701.txt\n",
      "[REMOVED] 702.txt\n",
      "[REMOVED] 703.txt\n",
      "[REMOVED] 704.txt\n",
      "[REMOVED] 705.txt\n",
      "[REMOVED] 706.txt\n",
      "[REMOVED] 707.txt\n",
      "[REMOVED] 708.txt\n",
      "[TRAIN] Images: 697, Labels: 697\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "split = \"train\"\n",
    "labels_dir = rf\"D:\\Downloads\\projectù\\merged_dataset\\{split}\\labels\"\n",
    "images_dir = rf\"D:\\Downloads\\projectù\\merged_dataset\\{split}\\images\"\n",
    "\n",
    "# Lister toutes les images\n",
    "image_files = [f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "# Créer un dictionnaire pour savoir quels labels garder\n",
    "labels_to_keep = {}\n",
    "\n",
    "for img in image_files:\n",
    "    # Chercher tous les fichiers de label qui contiennent le nom de l'image\n",
    "    base = os.path.splitext(img)[0]\n",
    "    matching_labels = [f for f in os.listdir(labels_dir) if f.startswith(base)]\n",
    "    \n",
    "    if not matching_labels:\n",
    "        continue\n",
    "\n",
    "    # Priorité : YOLOv8 *_rf_*.txt\n",
    "    yolo8_labels = [f for f in matching_labels if \"_rf\" in f]\n",
    "    if yolo8_labels:\n",
    "        # garder le premier YOLOv8 trouvé\n",
    "        labels_to_keep[img] = yolo8_labels[0]\n",
    "    else:\n",
    "        # sinon, garder JSON (*.jpg.txt ou *.txt)\n",
    "        labels_to_keep[img] = matching_labels[0]\n",
    "\n",
    "# Supprimer tous les labels qui ne sont pas dans labels_to_keep.values()\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file not in labels_to_keep.values():\n",
    "        os.remove(os.path.join(labels_dir, label_file))\n",
    "        print(f\"[REMOVED] {label_file}\")\n",
    "\n",
    "# Vérification finale\n",
    "num_images = len([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "num_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith(\".txt\")])\n",
    "print(f\"[{split.upper()}] Images: {num_images}, Labels: {num_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "107a301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Images: 697, Labels: 697\n",
      "[VALID] Images: 41, Labels: 41\n",
      "[TEST] Images: 142, Labels: 142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Chemin du dossier fusionné\n",
    "general_path = r\"D:\\Downloads\\projectù\\merged_dataset\"\n",
    "\n",
    "# Vérification des splits\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    images_dir = os.path.join(general_path, split, \"images\")\n",
    "    labels_dir = os.path.join(general_path, split, \"labels\")\n",
    "\n",
    "    # Compter images (.jpg ou .png)\n",
    "    num_images = len([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    # Compter labels (.txt)\n",
    "    num_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith(\".txt\")])\n",
    "\n",
    "    print(f\"[{split.upper()}] Images: {num_images}, Labels: {num_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b9dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07110a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
